{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import  numpy as np\n",
    "from glob import glob\n",
    "from scipy import misc\n",
    "import os, cv2, random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsAndCatsHelper:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data():\n",
    "        \n",
    "        TRAIN_DIR = 'C:/Users/Xiangyu Gao/Downloads/train/'\n",
    "        TEST_DIR = 'C:/Users/Xiangyu Gao/Downloads/test1/'\n",
    "\n",
    "        ROWS = 227\n",
    "        COLS = 227\n",
    "        CHANNELS = 3\n",
    "        print(os.listdir(TRAIN_DIR)[:5])\n",
    "        train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "        train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "        train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "        test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "\n",
    "        # slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n",
    "        train_images = train_dogs[:] + train_cats[:]\n",
    "        random.shuffle(train_images)\n",
    "        test_images =  test_images[:]\n",
    "\n",
    "        def read_image(file_path):\n",
    "            img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "            return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "        def prep_data(images):\n",
    "            count = len(images)\n",
    "            data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "            for i, image_file in enumerate(images):\n",
    "                image = read_image(image_file)\n",
    "                data[i] = image.T\n",
    "                if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "            \n",
    "            return data\n",
    "\n",
    "        train = prep_data(train_images[0:5000])\n",
    "        test = prep_data(test_images[0:5000])\n",
    "        train = np.swapaxes(train, 1,3)\n",
    "        test = np.swapaxes(test, 1,3)\n",
    "\n",
    "        print(\"Train shape: {}\".format(train.shape))\n",
    "        print(\"Test shape: {}\".format(test.shape))\n",
    "        labels = []\n",
    "        \n",
    "        for i in train_images:\n",
    "            if 'dog' in i.split('/')[-1]:\n",
    "                labels.append([1,0])\n",
    "            else:\n",
    "                labels.append([0,1])\n",
    "\n",
    "        #sns.countplot(labels).set_title('Cats and Dogs')\n",
    "        labels = np.array(labels[0:5000])\n",
    "\n",
    "        return train, labels, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet:\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size = 32,\n",
    "                 epochs = 100):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_size: number of examples per batch_size\n",
    "            epochs: number of iterations over all training examples\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "    @staticmethod\n",
    "    def inference(images, num_classes):\n",
    "        \"\"\"Builds AlexNet Graph\n",
    "\n",
    "        Args:\n",
    "            images: train/test images\n",
    "            num_classes: number of classes\n",
    "        Returns:\n",
    "            final_node: last node in the graph\n",
    "        \"\"\"\n",
    "\n",
    "        # Layer 1\n",
    "        with tf.name_scope(\"conv1\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W1', [11, 11, 3, 96])\n",
    "            conv = tf.nn.conv2d(images, kernel, [1, 4, 4, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b1', [96])\n",
    "            conv1 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm1') as scope:\n",
    "            mean, var = tf.nn.moments(conv1, [0, 1, 2])\n",
    "            batch_norm1 = tf.nn.batch_normalization(conv1, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        with tf.name_scope('pool1') as scope:\n",
    "            pool1 = tf.nn.max_pool(batch_norm1, [1, 3, 3, 1], [1, 2, 2, 1], padding='SAME', name=scope)\n",
    "\n",
    "        # Layer 2\n",
    "        with tf.name_scope(\"conv2\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W2', [5, 5, 96, 256])\n",
    "            conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b2', [256])\n",
    "            conv2 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm2') as scope:\n",
    "            mean, var = tf.nn.moments(conv2, [0, 1, 2])\n",
    "            batch_norm2 = tf.nn.batch_normalization(conv2, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        with tf.name_scope('pool2') as scope:\n",
    "            pool2 = tf.nn.max_pool(batch_norm2, [1, 3, 3, 1], [1, 2, 2, 1], padding='SAME', name=scope)\n",
    "\n",
    "        # Layer 3\n",
    "        with tf.name_scope(\"conv3\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W3', [3, 3, 256, 384])\n",
    "            conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b3', [384])\n",
    "            conv3 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm3') as scope:\n",
    "            mean, var = tf.nn.moments(conv3, [0, 1, 2])\n",
    "            batch_norm3 = tf.nn.batch_normalization(conv3, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        # Layer 4\n",
    "        with tf.name_scope(\"conv4\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W4', [3, 3, 384, 384])\n",
    "            conv = tf.nn.conv2d(batch_norm3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b4', [384])\n",
    "            conv4 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm4') as scope:\n",
    "            mean, var = tf.nn.moments(conv4, [0, 1, 2])\n",
    "            batch_norm4 = tf.nn.batch_normalization(conv4, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        # Layer 5\n",
    "        with tf.name_scope(\"conv5\") as scope:\n",
    "            kernel = AlexNetHelper.instintiate_weights('W5', [3, 3, 384, 256])\n",
    "            conv = tf.nn.conv2d(batch_norm4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = AlexNetHelper.instintiate_bias('b5', [256])\n",
    "            conv5 = tf.nn.relu(tf.nn.bias_add(conv, biases), name=scope)\n",
    "\n",
    "        with tf.name_scope('batch_norm5') as scope:\n",
    "            mean, var = tf.nn.moments(conv5, [0, 1, 2])\n",
    "            batch_norm5 = tf.nn.batch_normalization(conv5, mean, var, 0, 1, 0, name=scope)\n",
    "\n",
    "        with tf.name_scope('pool5') as scope:\n",
    "            pool5 = tf.nn.max_pool(batch_norm5, [1, 3, 3, 1], [1, 2, 2, 1], padding='SAME', name=scope)\n",
    "\n",
    "        # Fully Connected 6\n",
    "        with tf.name_scope('FC6') as scope:\n",
    "            pool5_flat = tf.contrib.layers.flatten(pool5)\n",
    "            fc6 = tf.layers.dense(pool5_flat, units=4096, activation=tf.nn.relu, name=scope)\n",
    "            # fc6_dropout = tf.layers.dropout(fc6, 0.5)\n",
    "\n",
    "        with tf.name_scope('FC7') as scope:\n",
    "            fc7 = tf.layers.dense(fc6, units=4096, activation=tf.nn.relu, name=scope)\n",
    "            # fc7_dropout = tf.layers.dropout(fc7, 0.5)\n",
    "\n",
    "        with tf.name_scope('classes') as scope:\n",
    "            predictions = tf.layers.dense(fc7, units=num_classes, activation=tf.nn.softmax, name=scope)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runtime for AlexNet\n",
    "        :param\n",
    "        train_data: training data\n",
    "        num_classes: num_classes\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        train_images, train_labels, valid_images= DogsAndCatsHelper.get_data()\n",
    "        num_classes = train_labels.shape[1]\n",
    "\n",
    "        images = tf.placeholder(tf.float32, shape=[None, *train_images[0].shape])\n",
    "        labels = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "        predictions = self.inference(images, num_classes)\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = predictions, labels = labels))\n",
    "        #loss = tf.nn.l2_loss(tf.square(predictions - labels))\n",
    "        learner = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
    "        optimizer = learner.minimize(loss)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            for ep in range(self.epochs):\n",
    "                start_time = time.time()\n",
    "                l_total = 0\n",
    "                acc = 0\n",
    "                for i in range(0, len(train_images), self.batch_size):\n",
    "                    l, acc, _ = sess.run(fetches=[loss, accuracy, optimizer],\n",
    "                                         feed_dict={images: train_images[i: self.batch_size + i],\n",
    "                                                    labels: train_labels[i: self.batch_size + i]})\n",
    "                    l_total += np.sum(l)\n",
    "                use_time = time_time() - start_time\n",
    "                print(\"EPOCH {0}, training time {1:.4f}s, training Accuracy = {2:.3f}\".format(ep, use_time, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetHelper:\n",
    "    @staticmethod\n",
    "    def instintiate_weights(key, shape):\n",
    "        return tf.get_variable(key,\n",
    "                               shape=shape,\n",
    "                               initializer=tf.contrib.layers.variance_scaling_initializer(factor=2.0,\n",
    "                                                                                          mode='FAN_IN',\n",
    "                                                                                          uniform=False,\n",
    "                                                                                          seed=None,\n",
    "                                                                                          dtype=tf.float32))\n",
    "\n",
    "    @staticmethod\n",
    "    def instintiate_bias(key, shape):\n",
    "        return tf.Variable(tf.constant(0.1, dtype=tf.float32, shape=shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.1000.jpg']\n",
      "Train shape: (25000, 227, 227, 3)\n",
      "Test shape: (12500, 227, 227, 3)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Xiangyu Gao\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py:97: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value beta2_power\n\t [[node beta2_power/read (defined at C:\\Users\\Xiangyu Gao\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py:129) ]]\n\nCaused by op 'beta2_power/read', defined at:\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3220, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-f0c9d953ff7f>\", line 4, in <module>\n    alex_net.run()\n  File \"C:\\Users\\Xiangyu Gao\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py\", line 129, in run\n    optimizer = learner.minimize(loss)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 413, in minimize\n    name=name)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 595, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 131, in _create_slots\n    colocate_with=first_var)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 828, in _create_non_slot_variable\n    colocate_with))\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3889, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value beta2_power\n\t [[node beta2_power/read (defined at C:\\Users\\Xiangyu Gao\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py:129) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value beta2_power\n\t [[{{node beta2_power/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f0c9d953ff7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0malex_net\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0malex_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m                     l, acc, _ = sess.run(fetches=[loss, accuracy, optimizer],\n\u001b[0;32m    141\u001b[0m                                          feed_dict={images: train_images[i: self.batch_size + i],\n\u001b[1;32m--> 142\u001b[1;33m                                                     labels: train_labels[i: self.batch_size + i]})\n\u001b[0m\u001b[0;32m    143\u001b[0m                     \u001b[0ml_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value beta2_power\n\t [[node beta2_power/read (defined at C:\\Users\\Xiangyu Gao\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py:129) ]]\n\nCaused by op 'beta2_power/read', defined at:\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3220, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-f0c9d953ff7f>\", line 4, in <module>\n    alex_net.run()\n  File \"C:\\Users\\Xiangyu Gao\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py\", line 129, in run\n    optimizer = learner.minimize(loss)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 413, in minimize\n    name=name)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 595, in apply_gradients\n    self._create_slots(var_list)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 131, in _create_slots\n    colocate_with=first_var)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 828, in _create_non_slot_variable\n    colocate_with))\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3889, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Xiangyu Gao\\AppData\\Local\\conda\\conda\\envs\\ee596b\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value beta2_power\n\t [[node beta2_power/read (defined at C:\\Users\\Xiangyu Gao\\Documents\\GitHub\\Practical-Introduction-NN-hw\\hw2\\AlexNet.py:129) ]]\n"
     ]
    }
   ],
   "source": [
    "from AlexNet import AlexNet\n",
    "tf.reset_default_graph()\n",
    "alex_net = AlexNet()\n",
    "alex_net.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
